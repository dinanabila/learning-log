# 2026/01/04

## Accomplishments
- Mencari dan mempelajari jawaban dari pertanyaan pemandu untuk ngerjain Kriteria 3 submission kelas Dicoding Deep Learning Tingkat Mahir:
    1. Jelasin tentang:
        - Custom Training
            - Kalau yang biasanya itu kan kalau mau ngelatih model itu pakainya sintaks model.fit() sama model.compile() tanpa bener-bener merhatiin apa-apa aja yang sebenernya terjadi di baliknya. Pokoknya, yang penting, ngelatih aja. Udah. 
            - Kalau dipelajari lagi, proses pelatihan deep learning itu kan terdiri dari beberapa proses. Dimulai dari input data, terus latih modelnya pakai input data tadi dengan weight awal, lalu hitung loss nya, abistu hitung gradien dari fungsi loss terhadap parameter model, baru deh abis itu perbarui bobot berdasarkan gradien yang udah dihitung tadi, dan balik lagi nge-loop ke awal ke proses pelatihan lagi sampai si loss nya itu cilik secilik-ciliknya yang diinginkan a.k.a sampai optimal. 
            - Terus kenapa banget kita masih perlu meng-custom proses training ini pakai Custom Training? Ya ga ada ruginya sih. Ibarat nih, misalkan katakan selama ini kamu pakai mobil yang mesin + tool kemudinya emang udah dirancang dari sananya dari pabrik dan kamu tinggal pake, nah, kali ini kamu rakit mobilnya sendiri itu include si daleman-daleman mesinnya beserta tool kemudinya kek setirnya, persenelingnya, remnya dkk nya, itu semua kamu yang atur dah. Biar apa banget? Biar sesuai sama yang benar-benar kita butuhkan. Kek, misalkan kamu selama ini ga puas sama kinerja wiper bawaan pabrik karena kurang mengibas air hujan, nah karena kamu yang kali ini ngerakit sendiri, kamu juga yang bisa atur tu wiper mau gerak gimana biar mata bebas dari air hujan, lebih bebas dari wiper mobil hasil produksi bawaan pabrik. Kek misalkan juga ada sesuatu di mesin yang kamu pengen improve, misal, kamu pengen si mesin nya ga kentut-kentut tiap pindah perseneling. Nah itu kamu juga bisa atur di rakitannya biar ga kentut lagi. Jadi, antara hasil rakitan dengan hasil versi pabrikan memang bisa sama-sama jalan dengan tujuan yang sama, tapi bedanya hasil rakitanmu lebih bisa memenuhi yang kamu butuhkan. 
        - tf.GradientTape
            - Ini untuk fasiitasin proses perhitungan gradien di custom training model. Jadi kalau pakai ini, kita ga perlu bikin lagi rumus turunan secara manual.  
        - Loop Training
            - Nyambung sama penjelasan Custom Training. Proses pelatihan deep learning itu pada dasarnya loop. Itulah yang dinamakan Loop Training. 
        - Autoregressive
            - Autoregressive maksudnya adalah setiap langkah prediksi itu bergantung dengan hasil dari prediksi sebelumnya. Untuk case time series forecasting lstm seq2seq kali ini, kita ga pakai model.predict() buat melakukan inference. Jadi perlu bikin fungsi baru buat fasilitasin proses prediksi berbasis autoregressive. 
    
    2. Gimana cara membangun custom training dengan tf.GradientTape?
        - Kaitkan tf.GradientTape dengan proses perhitungan loss dan weight sama bias awalnya. Dibikin dalam satu fungsi. Detail contohnya ada di submodul Automatic Differentiation dengan tf.GradientTape. 

    3. Gimana cara melakukan inference dengan teknik autoregressive?
        - Caranya dengan mengatur loop kerjaan decoder dan encoder sedemikian sehingga autoregressive terpenuhi. Detailnya ada di submodul Latihan Sequence to Sequence. 

    4. Gimana cara membangun fungsi loss MAE dari awal dengan Custom Loss?
        - Bikin pakai class, tapi pakai fungsi biasa juga bisa keknya, cuman lebih rapi pakai class. Class nya mewarisi class Loss nya tensorflow. Detail caranya ada di submodul Kustomisasi Loss Function. Disesuaikan aja rumusnya pakai rumus MAE.  

    5. Gimana cara menggunakan Custom Loss pada Custom Training?
        - Ini tinggal dipanggil aja nanti di dalam Custom Training nya. Nanti bakal make sense dengan sendirinya kayak pasang kepingan puzzle. 

    6. Gimana cara membangun fungsi callback early stopping dari awal dengan Custom Callback? 
        - Bikinnya pakai class dengan mewarisi Callback nya tensorflow. Detailnya ada di submodul Kustomisasi Callback. 

    7. Gimana cara menggunakan Custom Callback pada Custom Training?
        - Ini juga sama kayak custom loss, tinggal dipanggil aja nanti di dalam Custom Training nya. Disesuaikan aja. 

    8. Gimana cara membangun Custom Loss yang bisa menambahkan weight loss pada horizon atau step yang lebih jauh? 
        - Ini ternyata ada contohnya di instruksi submission. Tinggal disesuaiin aja rumusnya di mae nya. 

    9. Gimana cara membangun Custom Callback yang dapat mengurangi learning rate secara bertahap saat validation loss nya stagnan selama beberapa epoch?
        - Pakein if else mungkin. Belum tau, ntar dipikirkan dan direncanakan lagi. Ga dikasitau juga caranya di modul soalnya. 


## Thoughts
-  Jadi output kerjaan Kriteria 3 itu Custom Training buatan sendiri yang memanfaatkan tf.GradientTape untuk proses perhitungan gradiennya, yang mana hasil pelatihan dari Custom Training tersebut digunakan untuk melakukan inferensi prediksi dengan teknik Autoregressive. Loop Training dari Custom Training yang dibangun juga harus menampilkan jumlah epoch, loss, dan val loss selama berjalan.
- Untuk kriteria Skilled, loss nya harus Custom, bangun dari nol. Pakai MAE. Bikin juga callback early stopping custom, bangun dari nol juga. Pasang keduanya di Custom Training yang udah dibangun. 
- Untuk kriteria Advanced, loss custom yang udah dibikin tadi harus dimodif lagi alias di-upgrade, dia harus bisa nambahin weight loss pada horizon atau step yang lebih jauh. Terus juga custom callback nya juga di-upgrade supaya bisa mengurangi learning rate secara bertahap saat validation loss nya stagnan selama beberapa epoch. Pasang kedua custom-an upgrade-an tadi di Custom Training yang udah dibangun. Sama, selain itu ada ketentuan tambahan juga untuk memenuhi kriteria Advanced: performa model custom Seq2Seq LSTM saat dievaluasi pada data test di bawah 0.015 MAE (kondisi sebelum di-inverse scaled). 

## Next Steps
- Bikin kerangka kode untuk ngerjain submission nya. 
