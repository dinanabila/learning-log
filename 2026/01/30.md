# 2026/01/30

## Accomplishments
- "gimana cara model lstm biasa mencerna dan mempelajari data sliding window?" --> sama kayak halnya gimana model ml mencerna dataset yang diterimanya untuk tugas klasifikasi. Semua window nya itu terpakai untuk melatih model lstm, entah itu lstm biasa, maupun lstm seq2seq.
- di mana tepatnya bedanya seq2seq dengan recursive dan direct multistep? ternyata bukan di autoregressive, melainkan di arsitektur seq2seq itu sendiri. seq2seq boleh kok pakai teacher forcing, dan boleh juga pakai autoregressive. yang bedain itu, kalau seq2seq itu pakai encoder & decoder, sementara yang lain ngga. 
- kalau recursive multistep itu, dia sifatnya autoregressive yang pakai data dari hasil prediksi timestep sebelumnya untuk memprediksi data timestep setelahnya. tapinya jadi rentan error yang terakumulasi dari timestep ke timestep. 
- kalau direct multistep, dia itu memprediksi seluruh horizon sekaligus, sehingga oke, dia ga kayak recursive yang rentan mengalami error accumulation. tapi, direct multistep ini kurang fleksibel, soalnya horizon output nya terikat ke arsitektur model, dan jadi perlu retraining jika horizon berubah.
- kalau seq2seq, dia pakai arsitektur encoder-decoder yang menghasilkan output secara bertahap melalui state decoder. ini yang bisa bikin seq2seq mampu memodelkan dependensi antar timestep output. jadi bayanginnya itu, misal nih input nya itu 3 hari ke belakang, dengan target 2 hari ke depan. nah si semua data window yang udah dicerna encoder, itu diproses si encoder sampai membentuk "pengetahuan" yang dibungkus ke dalam vektor "state", dan selanjutnya yang diteruskan ke decoder itu si vektor state ini, bukan lagi dalam bentuk data window. apa yang terjadi di decoder? yang terjadi adalah, si decoder memprediksi data timestep sejumlah horizon data target secara bertahap. dalam case 2 horizon, berarti si decoder memprediksi data timestep pertama menggunakan state fresh dari encoder beserta ground truth data aktual target timestep pertama. terus, setelah itu decoder menghasilkan state yang diperbarui dari hasil prediksi timestep pertama itu, dan lalu si state terbaru beserta hasil prediksi timestep pertama ini dipakai untuk memprediksi data timestep kedua (kalau autoregressive ya). kalau teacher forcing, data timestep keduanya diprediksi pakai state terbaru sama data aktual timestep pertama, bukan data hasil prediksi timestep pertama.
- kalau di case submission kelas dltm, pas training seq2seq nya pakai teacher forcing (pakai ground truth sebagai input decoder), dan baru pakai autoregressive pas inference. 
- seq2seq, dalam hal ini, jadi lebih fleksibel dibanding direct multistep, dan juga lebih stabil saat training dibanding recursive murni, meskipun memang pas inference nya tetap mengalami akumulasi error. gapapa si, yang penting pas training nya ga terjadi penumpukan error. 

## Thoughts
- yang masih perlu dipahami: bedanya proses pas training, evaluasi, dan inference. 

## Next Steps
- pending time series forecasting. perlu fokus nlp dulu. 