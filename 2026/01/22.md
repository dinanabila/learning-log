# 2026/01/22

## Accomplishments

- Eh aku salah nangkep kemarin. Ternyata ACF juga dibahas di modul kaggle nya.
- ACF, akronimnya AutoCorrelation Function. Dia itu lag plot yang kulampirin contohnya di learning log dua hari yang lalu, tanggal 20.
- Bedanya ACF dan PACF, kalau ACF itu dia ngasitau korelasi antara lag dengan si data dari sejumlah lag yang bersangkutan, tanpa misahin dampak dari lag-lag sebelumnya / di antara si lag itu dengan si data observasi. Kalau PACF, dia bener-bener pure ngasitau korelasi antar lag dan data observasi, yang bener-bener bersih tanpa ada keterlibatan dari lag-lag sebelumnya.
- Contohnya, kalau ACF, si korelasi antara lag 2 dengan data observasi itu bisa jadi masih ada bagian lag 1 yang "ikut campur". Sementara kalau PACF, itu si lag 1 nya udah ga ada ikut-ikut kecampur lagi di korelasi antara lag 2 dan data observasi.
- Dalam konteks machine learning, ACF berguna untuk melihat, apakah data time series yang kita gunakan itu relevan atau ga kalau pakai lag buat dijadiin fitur. Kalau sekiranya ternyata dari ACF itu ga keliat ada korelasi sama sekali antar data tanggal observasi dengan data lag nya, berarti bisa disimpulkan kalau lag ga worth it buat dijadikan fitur untuk melatih model.
- Sementara PACF, faedahnya dalam konteks machine learning adalah untuk menghindari redundansi fitur. Idenya, kita ga mau pakai lag yang ternyata udah ga ngasih informasi fresh lagi. Ga fresh ini artiannya kalau dilihat dari konteks ACF, itu ga fresh yang dikarenakan korelasi yang terbentuk itu ternyata sebenernya mayoritas itu korelasi antar lag sebelumnya, bukan dari si lag yang sekarang. Nah kalau pakai PACF, kita bisa tau, oh, si lag ini ternyata udah ga ngasih informasi apa-apa lagi, soalnya udah diwakilkan lag sebelumnya.
ACF, artinya, dalam hal ini bisa kita bayangkan sebagai hubungan data antar waktu ke waktu yang korelasinya itu mengandung unsur efek domino. Kalau PACF udah ga ada efek domino lagi karena pengaruh antar domino nya terhapuskan.
- Kalau misalkan kita mau menentukan window size untuk LSTM Seq2Seq, artinya yang kita lihat itu ACF, bukan PACF, soalnya yang mau kita tahu itu, sampai seberapa jauh ke belakang data masih punya informasi yang berguna? Atau dengan kata lain, sampai sejauh mana efek domino itu ada?
- Better ambil window size yang seterkecil mungkin, atau ambil yang gede setergede mungkin? Yang kecil. Soalnya kalau yang besar, mahal komputasi dan risiko overfitting sebab model terlalu belajar dari data yang banyak + noise. Terus juga, kalau pilih yang besar itu ibarat, suruh aja LSTM nya ngelatih dirinya sendiri dengan semua data, ngapain repot-repot nentuin window size lagi.

## Thoughts
- Jadi selain bisa untuk menentukan window size, ACF itu ibarat untuk lihat gambaran besar, buat tau, lag itu worth it atau ga buat dijadiin fitur. Sementara PACF lebih ke untuk nentuin, sampai lag berapa yang bener-bener worth it buat dijadiin fitur.

## Next Steps
- Lanjut belajar di kaggle learn time series. Kalau bisa kelarin semua besok.
